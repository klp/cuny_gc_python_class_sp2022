{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a50c60b7-53d9-4f00-8c2d-a044d4232d71",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text Analysis Assignment\n",
    "\n",
    "## Assignment Details\n",
    "\n",
    "The text below is a summary from [this document](https://docs.google.com/document/d/1FNRmAS_vc-2eQESHH6uZMcuDVr720rsx-aDWGH3oz_Y/edit?usp=sharing).\n",
    "\n",
    "The main goal of the assignment is to have you practice the tools we have been using in class.\n",
    "\n",
    "The requirements are:\n",
    "\n",
    "- Choose one or more texts to work with.\n",
    "- Either save the text files in your working directory, or have python get them from a web address.\n",
    "- If needed: convert your text from bytes to a string\n",
    "- Tokenize your text\n",
    "- Make it an NLTK text object so you can use nltk tools on it\n",
    "- Clean the text in a way that is appropriate for the kind of analysis you want to do.\n",
    "- Run some analysis\n",
    "- Report findings\n",
    "\n",
    "Important notes:\n",
    "\n",
    "- If you plan to use functions, have your functions as a separate python file and import it in your main file.\n",
    "\n",
    "- Please, over-comment your script. Make sure to comment every step of the way. Make sure to not only explain what you are doing in terms of code, but also your analytical goal too. For instance, both \"I am running a for loop to remove the common words\" and \"I am trying to see how these two authors compare in terms of the ratio of unusual words to total words\" are kind of comments I want to see.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54381b50-b167-446f-a52f-a9dbcef7138f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assignment Submission\n",
    "\n",
    "### Itinerary\n",
    "\n",
    "I want to compare usage of modal verbs in American/English men and women authors from 19th century / early 20th literature. I wonder if there is any difference based on nationality or gender. To do my proposed analysis, I will:\n",
    "\n",
    "- Download a sample of raw texts from [Project Gutenberg](https://www.gutenberg.org/) using `urllib`\n",
    "- Convert the texts from bytes to a string\n",
    "- Tokenize the texts\n",
    "- Make it an NLTK text object\n",
    "- Clean the texts, including removing front matter and other empherma from Project Gutenberg texts\n",
    "- Create a list of modal verbs, filter for these works in each text\n",
    "- Perhaps create a conditional frequency distribution on all texts (?) to see if we can establish a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df213cb-fb26-43f8-b3da-ef723c5f41d1",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "In the cell below, I'm importing the libraries/modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f854c78-7e9c-4af8-9ea1-41bc46171f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b94b9c-492b-44ab-96f0-9307bda69443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kaiprenger/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen                    # requesting and opening a file on the internet\n",
    "import nltk                                           # our tool for text analysis\n",
    "nltk.download('punkt')                                # required to run word_tokenized() initially\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from helper_funcs import lowered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0558354b-d20c-4a56-9dbc-4cd32264467b",
   "metadata": {},
   "source": [
    "### Collecting the texts from Project Gutenberg\n",
    "\n",
    "The first step is to get the raw texts from Project Gutenburg. This work is demonstrated in the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e51d09-8732-42a4-9ff9-420a40db8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables for each plain text file on PG\n",
    "custom_of_country_url = 'https://www.gutenberg.org/cache/epub/11052/pg11052.txt'\n",
    "little_dorrit_url = 'https://www.gutenberg.org/files/963/963-0.txt'\n",
    "persuasion_url = 'https://www.gutenberg.org/cache/epub/105/pg105.txt'\n",
    "the_awkward_age_url = 'https://www.gutenberg.org/files/7433/7433-0.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31a5174-2a2b-4d4e-b901-46fcac4db4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open URLs\n",
    "custom_country_file = urlopen(custom_of_country_url)\n",
    "little_dorrit_file = urlopen(little_dorrit_url)\n",
    "persuasion_file = urlopen(persuasion_url)\n",
    "the_awkward_age_file = urlopen(the_awkward_age_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d820d95-ea9d-4b0b-8c05-c395213ac821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the texts and assign them to a variables\n",
    "custom_country_raw = custom_country_file.read()\n",
    "little_dorrit_raw = little_dorrit_file.read()\n",
    "persuasion_raw = persuasion_file.read()\n",
    "the_awkward_age_raw = the_awkward_age_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf98c4f-5bf2-41d0-9925-a2451bb94d0b",
   "metadata": {},
   "source": [
    "### Converting the raw text to strings and lists\n",
    "\n",
    "Below, I demonstrate that while we have the texts available, they're in a format that isn't conducive to text analysis. We will convert these UTF-8 bytes to strings, and finally, to lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1f56ba-5b8c-4ff9-af31-9cd3b478f2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check type for a given text\n",
    "type(little_dorrit_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f4d531-797b-478f-9806-c70439093266",
   "metadata": {},
   "source": [
    "If you were run `little_dorrit_raw` you'll notice when the text is in bytes, you'll get unicode embedded into the text (e.g. `b'\\xef\\xbb\\xbf\\r\\n`). Next, we will decode the raw files into a string to make it more usable for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a8ae2d4-1561-4c34-9feb-e364d9b544e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_of_country = custom_country_raw.decode()\n",
    "little_dorrit = little_dorrit_raw.decode()\n",
    "persuasion = persuasion_raw.decode()\n",
    "awkward_age = the_awkward_age_raw.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3674c4f-ae15-4580-a28a-da2d5425216e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type for a given text\n",
    "type(awkward_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b637f11-f361-44b2-b26c-d18820715713",
   "metadata": {},
   "source": [
    "At this point, the entire text is a string, which provides a grain per letter of the text and may not be super useful for a text analysis. Below you'll see slicing into the text by the first 50 characters to see what we mean by not useful.\n",
    "\n",
    "Side note: If you were to run `awkward_age` you would continue to see unicode like `'\\ufeff`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58597af-4f00-48ed-bd04-05eaf0d46433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of The Awkward Age, b'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awkward_age[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f09f5f-a49c-4385-8c94-f96a9b765f0d",
   "metadata": {},
   "source": [
    "Next, we'll tokenize the text, in order to create a list of strings made up of each discrete element separated by spaces (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333eb7fd-066f-4205-8c1a-d2a24db90ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "awkward_age_tokens = nltk.word_tokenize(awkward_age)\n",
    "custom_of_country_tokens = nltk.word_tokenize(custom_of_country)\n",
    "little_dorrit_tokens = nltk.word_tokenize(little_dorrit)\n",
    "persuasion = nltk.word_tokenize(persuasion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21d37d8a-4d38-4369-b711-250e5f147815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Awkward',\n",
       " 'Age',\n",
       " ',',\n",
       " 'by',\n",
       " 'Henry',\n",
       " 'James',\n",
       " 'This',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever',\n",
       " '.',\n",
       " 'You',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it',\n",
       " ',',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'License']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate that the tokens are words\n",
    "awkward_age_tokens[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b109b0-a012-4555-a935-4589fce90eab",
   "metadata": {},
   "source": [
    "### Prepping the text\n",
    "With these texts coming from Project Gutenberg (PG), we'll need to clean up front matter etc. I will do this by\n",
    "\n",
    "1. Inspecting the first relevant words of a novel \n",
    "2. Identify what I believe to be the word which is likely to not be a part of the front matter that GP adds\n",
    "3. Find the index of the word above in the word tokenized list for the novel\n",
    "4. Perform a slice to make sure the first relevant sentence if selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f26ef-c869-4263-94c5-bc18795760dc",
   "metadata": {},
   "source": [
    "#### Prepping the Awkward Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a259b2d-9280-47b8-93e4-a4e92fadaa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awkward_age_tokens.index('recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b6a206-b8ff-4ca6-b3c4-32c9d9e13e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'recall', 'with', 'perfect', 'ease']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awkward_age_tokens[126:131]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e5c65-0b97-4d02-812d-3c2bacdbcabe",
   "metadata": {},
   "source": [
    "We'll start our slice for `awkward_age_tokens` at 126. But we also need end the slice to remove post-novel text and license information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bd38daf-a0aa-468d-9f41-e87316b0102a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Archive',\n",
       " 'Foundation',\n",
       " ',',\n",
       " 'how',\n",
       " 'to',\n",
       " 'help',\n",
       " 'produce',\n",
       " 'our',\n",
       " 'new',\n",
       " 'eBooks',\n",
       " ',',\n",
       " 'and',\n",
       " 'how',\n",
       " 'to',\n",
       " 'subscribe',\n",
       " 'to',\n",
       " 'our',\n",
       " 'email',\n",
       " 'newsletter',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'about',\n",
       " 'new',\n",
       " 'eBooks',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awkward_age_tokens[-25:]    # Inspecting the end of the text to find this out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db21ef-a92a-4f63-9ce3-b2e61937aae0",
   "metadata": {},
   "source": [
    "I decided to approximate where the novel ends here by looking at the producer name of this text version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49405cad-90fe-4f55-ba39-746d27a125cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awkward_age_tokens.index('Sobol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "544e2b68-0106-4b04-8f0a-2c61bd7aeb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sobol'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awkward_age_tokens[118]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d4e4a-22b1-4f8a-be23-f72ed2c2acd3",
   "metadata": {},
   "source": [
    "The method above doesn't work, because the name is mentioned at the beginning. Let's look for the index from a slice beyond the index above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a89eb21-a0b6-4c77-96e6-6203681d8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "awkward_age_wo_pref = awkward_age_tokens[126:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b68ca4a7-36e2-4ba9-aa54-75a69e36a849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181183"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awkward_age_wo_pref.index('Sobol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e9f6edb-53f0-4fbe-a1e3-68c728f4b6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sobol'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awkward_age_wo_pref[181183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44d48734-fbaa-47d2-a992-fb4d9bb99524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'see',\n",
       " '.',\n",
       " 'There',\n",
       " 'we',\n",
       " 'are',\n",
       " '.',\n",
       " 'Well',\n",
       " ',',\n",
       " '”',\n",
       " 'said',\n",
       " 'Mr.',\n",
       " 'Longdon',\n",
       " '--',\n",
       " '“',\n",
       " 'to-morrow.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awkward_age_wo_pref[181100:181116]    # trying to nail down the index of the last word of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ac63c52-6e9d-4b08-a911-234b0ac61826",
   "metadata": {},
   "outputs": [],
   "source": [
    "awkward_age_tokens_sliced = awkward_age_wo_pref[:181116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "533fdcdb-7a9b-47c1-93a6-81615639af04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'recall', 'with', 'perfect', 'ease', 'the', 'idea']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awkward_age_tokens_sliced[:7]    # first seven tokens of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8599d15-5cfa-43e9-8094-0b2e9b29c2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Well', ',', '”', 'said', 'Mr.', 'Longdon', '--', '“', 'to-morrow.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awkward_age_tokens_sliced[-9:]    # last nine tokens of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11481e1f-c00d-4aba-885b-63abb5295d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove non-alphabet characters and convert all words to lower case\n",
    "awkward_age_tokens_prep = lowered(awkward_age_tokens_sliced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105dffcc-f36e-4c0f-8e9b-fea54f41cdfc",
   "metadata": {},
   "source": [
    "#### Prepping Custom of the Country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02a87b92-d208-40ba-800a-a9e66d2e9db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_of_country_tokens.index('Undine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f48ac7e9-051c-4909-8e64-689009b9647f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"''\", 'Undine', 'Spragg', '--', 'how', 'can', 'you', '?', \"''\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_of_country_tokens[126:135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d0e6264-d4ff-4b7f-b621-666ce9678627",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_of_country_token_no_pref = custom_of_country_tokens[126:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a146fffc-fde0-4027-aee1-a92453d24031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166205"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_of_country_token_no_pref.index('Proofreaders')    # in the producer name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b167d686-759d-42f9-81bd-842aabe31a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_of_country_token_no_pref[166129]    # last word in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0391df7e-e827-407c-bc51-6aec78ffb0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_of_country_tokens_sliced = custom_of_country_token_no_pref[:166131]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0122e72-3bcb-4d52-a549-1acc228a25a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['welcome',\n",
       " 'her',\n",
       " 'first',\n",
       " 'guests',\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " 'that',\n",
       " 'it',\n",
       " 'was',\n",
       " 'the',\n",
       " 'one',\n",
       " 'part',\n",
       " 'she',\n",
       " 'was',\n",
       " 'really',\n",
       " 'made',\n",
       " 'for',\n",
       " '.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_of_country_tokens_sliced[-20:]    # last twenty items after slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29ccc242-526f-4ad3-bbef-8e99f9aa5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_of_country_tokens_prep = lowered(custom_of_country_tokens_sliced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98729d7-802e-4dd0-974c-0594520ef2c5",
   "metadata": {},
   "source": [
    "#### Prepping Little Dorrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72cabfe-5af8-4b77-8dbc-26fe915aaf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
